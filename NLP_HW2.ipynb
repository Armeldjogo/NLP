{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpOeErK0LWvtgaPeZ3y8n9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armeldjogo/NLP/blob/main/NLP_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmKKsybh4GlU"
      },
      "source": [
        "Name: Armel Nsiangani\r\n",
        "\r\n",
        "Student ID#: 001-99-1988\r\n",
        "\r\n",
        "\r\n",
        "NLP - HW2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXGXsETYMsij"
      },
      "source": [
        "Question 1:\r\n",
        "\r\n",
        "Create a cosine similarity matrix for all of Shakespeareâ€™s works found in the provided file. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIebQPf4MxNg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "85dbadb2-26d4-4af2-cc40-1f842776c294"
      },
      "source": [
        "# Question 1\r\n",
        "import glob, os\r\n",
        "import numpy as np\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('punkt')\r\n",
        "\r\n",
        "\r\n",
        "os.chdir(\"/content/\")\r\n",
        "filesName = []\r\n",
        "for namefile in glob.glob(\"*.txt\"):\r\n",
        "    filesName.append(namefile)\r\n",
        "\r\n",
        "\r\n",
        "allDocuments = []\r\n",
        "for i in range(0,len(filesName)):\r\n",
        "  with open(\"/content/\" + filesName[i]) as openfile:\r\n",
        "    data = openfile.read()\r\n",
        "    allDocuments.append(data)\r\n",
        "\r\n",
        "stopWords = stopwords.words('english')\r\n",
        "vect = TfidfVectorizer(min_df=1, stop_words = stopWords)                                                                                                                                                                                                   \r\n",
        "tfidf = vect.fit_transform(allDocuments)                                                                                                                                                                                                                       \r\n",
        "pair_similarity = tfidf * tfidf.T \r\n",
        "sim_matrix = pair_similarity.toarray()\r\n",
        "\r\n",
        "\r\n",
        "print('-------------------------------------------------------------------------')\r\n",
        "print('The cosine identity matrix is below: ')\r\n",
        "print(sim_matrix)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------\n",
            "The cosine identity matrix is below: \n",
            "[[1.         0.09898043 0.12178397 ... 0.06968641 0.08012943 0.15890955]\n",
            " [0.09898043 1.         0.1198178  ... 0.17006317 0.07518287 0.15040131]\n",
            " [0.12178397 0.1198178  1.         ... 0.10302878 0.12821051 0.22090556]\n",
            " ...\n",
            " [0.06968641 0.17006317 0.10302878 ... 1.         0.06073003 0.10442782]\n",
            " [0.08012943 0.07518287 0.12821051 ... 0.06073003 1.         0.16985445]\n",
            " [0.15890955 0.15040131 0.22090556 ... 0.10442782 0.16985445 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yY9E3Cq4Wv0"
      },
      "source": [
        "Question 2:\r\n",
        "\r\n",
        "Write a function that takes the previous matrix and a number n as parameter (nothing else will be accepted) and return the top n similar works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K_RSHEg54Pzb",
        "outputId": "eebf0585-af6b-4beb-dc72-54223de63634"
      },
      "source": [
        "# Question 2\r\n",
        "def findMostSim(m,n):\r\n",
        "  array = np.around(m, decimals=3)\r\n",
        "  rArray = array.reshape(-1)\r\n",
        "  uN_Array = np.unique(rArray)\r\n",
        "  listVal = np.flip(uN_Array)\r\n",
        "  listVal = np.delete(listVal, np.where(listVal == 1))\r\n",
        "  valsOfInterest = listVal[0:n]\r\n",
        "  locVals = []\r\n",
        "  for i in range(0,len(valsOfInterest)):\r\n",
        "    rslt = np.where(array == valsOfInterest[i])\r\n",
        "    locVals.append(rslt[0].tolist())\r\n",
        "  print(\"The\",n,\"most similar works are in position: \")\r\n",
        "  print('-----------------------------------------')\r\n",
        "  for pos in locVals:\r\n",
        "    print(filesName[pos[0]],'and',filesName[pos[1]])\r\n",
        "\r\n",
        "# Print the result\r\n",
        "findMostSim(sim_matrix,10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 10 most similar works are in position: \n",
            "-----------------------------------------\n",
            "henry-iv-part-1_TXT_FolgerShakespeare.txt and henry-iv-part-2_TXT_FolgerShakespeare.txt\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt and shakespeares-sonnets_TXT_FolgerShakespeare.txt\n",
            "shakespeares-sonnets_TXT_FolgerShakespeare.txt and lucrece_TXT_FolgerShakespeare.txt\n",
            "venus-and-adonis_TXT_FolgerShakespeare.txt and lucrece_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-2_TXT_FolgerShakespeare.txt and henry-vi-part-3_TXT_FolgerShakespeare.txt\n",
            "henry-vi-part-1_TXT_FolgerShakespeare.txt and henry-vi-part-2_TXT_FolgerShakespeare.txt\n",
            "richard-iii_TXT_FolgerShakespeare.txt and henry-vi-part-3_TXT_FolgerShakespeare.txt\n",
            "richard-ii_TXT_FolgerShakespeare.txt and richard-iii_TXT_FolgerShakespeare.txt\n",
            "richard-ii_TXT_FolgerShakespeare.txt and henry-vi-part-3_TXT_FolgerShakespeare.txt\n",
            "the-merry-wives-of-windsor_TXT_FolgerShakespeare.txt and henry-iv-part-2_TXT_FolgerShakespeare.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDpIZlDR4kq7"
      },
      "source": [
        "Question 3:\r\n",
        "\r\n",
        "Using the code from the Language Models II class, train two simple language models using all of the files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8BXCznot30t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b80afdf1-b5b5-42ec-a54e-aa604530f37e"
      },
      "source": [
        "# Question 3\r\n",
        "import glob, os\r\n",
        "import numpy as np\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "import random\r\n",
        "import nltk\r\n",
        "#nltk.download('punkt')\r\n",
        "from nltk import bigrams, trigrams\r\n",
        "from collections import Counter, defaultdict\r\n",
        "\r\n",
        "# Import and store all shakespear work into 1 doc\r\n",
        "os.chdir(\"/content/\")\r\n",
        "filesName = []\r\n",
        "for namefile in glob.glob(\"*.txt\"):\r\n",
        "    filesName.append(namefile)\r\n",
        "\r\n",
        "with open(\"/content/\" + filesName[0]) as openfile:\r\n",
        "  allDocuments = openfile.readlines()\r\n",
        "\r\n",
        "for i in range(1,len(filesName)):\r\n",
        "  with open(\"/content/\" + filesName[i]) as openfile:\r\n",
        "    data = openfile.readlines()\r\n",
        "    allDocuments.append(data)\r\n",
        "\r\n",
        "allDoc_split = []\r\n",
        "for sent in allDocuments:\r\n",
        "  sent = ''.join(sent)\r\n",
        "  line = sent.split(\" \")\r\n",
        "  allDoc_split.append(line)\r\n",
        "\r\n",
        "# Create a placeholder for model\r\n",
        "model_1 = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "model_2 = defaultdict(lambda: defaultdict(lambda: 0))\r\n",
        "# Count frequency of co-occurence  \r\n",
        "for sentence in allDoc_split:\r\n",
        "    # Using trigrams\r\n",
        "    for w1, w2, w3 in trigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model_1[(w1, w2)][w3] += 1\r\n",
        "    # Using bigrams\r\n",
        "    for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\r\n",
        "        model_2[(w1)][w2] += 1 \r\n",
        "\r\n",
        "# Let's transform the counts to probabilities\r\n",
        "# Trigrmas\r\n",
        "for w1_w2 in model_1:\r\n",
        "    total_count = float(sum(model_1[w1_w2].values()))\r\n",
        "    for w3 in model_1[w1_w2]:\r\n",
        "        model_1[w1_w2][w3] /= total_count \r\n",
        "# Bigrams\r\n",
        "for w1_w2 in model_2:\r\n",
        "    total_count = float(sum(model_2[w1_w2].values()))\r\n",
        "    for w3 in model_2[w1_w2]:\r\n",
        "        model_2[w1_w2][w3] /= total_count\r\n",
        "\r\n",
        "# Testing the models\r\n",
        "\r\n",
        "#print('Using Trigrams')\r\n",
        "#print('-----------------')\r\n",
        "#dict(model_1[\"But\",\"now\"])\r\n",
        "\r\n",
        "\r\n",
        "print('Using Bigrams')\r\n",
        "print('-----------------')\r\n",
        "dict(model_2[\"king\"])\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Bigrams\n",
            "-----------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Charles': 0.005813953488372093,\n",
              " 'Charles,\\nFor': 0.005813953488372093,\n",
              " 'I': 0.011627906976744186,\n",
              " \"I'll\": 0.005813953488372093,\n",
              " 'King': 0.005813953488372093,\n",
              " 'adopt': 0.005813953488372093,\n",
              " 'again,\\nAnd': 0.005813953488372093,\n",
              " 'and': 0.1744186046511628,\n",
              " 'and\\na': 0.005813953488372093,\n",
              " 'at': 0.023255813953488372,\n",
              " 'be': 0.01744186046511628,\n",
              " 'blest': 0.005813953488372093,\n",
              " 'but': 0.023255813953488372,\n",
              " 'by': 0.005813953488372093,\n",
              " 'can': 0.005813953488372093,\n",
              " 'christen': 0.005813953488372093,\n",
              " 'crowned': 0.005813953488372093,\n",
              " 'dead?\\n\\nPISTOL\\nAs': 0.005813953488372093,\n",
              " 'double,': 0.005813953488372093,\n",
              " 'engenders': 0.005813953488372093,\n",
              " 'for': 0.011627906976744186,\n",
              " 'has': 0.005813953488372093,\n",
              " 'here': 0.005813953488372093,\n",
              " 'hereafter!\\n\\nBANQUO\\nGood': 0.005813953488372093,\n",
              " 'himself': 0.005813953488372093,\n",
              " 'his': 0.005813953488372093,\n",
              " 'in': 0.029069767441860465,\n",
              " 'indeed,': 0.005813953488372093,\n",
              " 'inter': 0.005813953488372093,\n",
              " 'is': 0.040697674418604654,\n",
              " 'is,\\nBeing': 0.005813953488372093,\n",
              " 'lies': 0.005813953488372093,\n",
              " 'like': 0.005813953488372093,\n",
              " 'loves': 0.005813953488372093,\n",
              " 'married': 0.005813953488372093,\n",
              " 'may': 0.011627906976744186,\n",
              " 'more': 0.005813953488372093,\n",
              " 'must': 0.005813953488372093,\n",
              " 'my': 0.011627906976744186,\n",
              " 'nor': 0.005813953488372093,\n",
              " \"o'\": 0.005813953488372093,\n",
              " \"o'er\": 0.011627906976744186,\n",
              " 'of': 0.20930232558139536,\n",
              " 'of\\nEngland,': 0.005813953488372093,\n",
              " 'on': 0.011627906976744186,\n",
              " 'or': 0.011627906976744186,\n",
              " 'perform.\\nAnd': 0.005813953488372093,\n",
              " 'perhaps--\\n\\nBUCKINGHAM': 0.005813953488372093,\n",
              " 'perplexed': 0.005813953488372093,\n",
              " 'purged': 0.005813953488372093,\n",
              " 'received.\\n\\nKING': 0.005813953488372093,\n",
              " 'shall': 0.005813953488372093,\n",
              " 'should': 0.011627906976744186,\n",
              " 'sigh,': 0.005813953488372093,\n",
              " 'so': 0.011627906976744186,\n",
              " 'succeed,\\nWhose': 0.005813953488372093,\n",
              " 'tempt': 0.005813953488372093,\n",
              " 'that': 0.040697674418604654,\n",
              " 'the': 0.005813953488372093,\n",
              " 'to': 0.023255813953488372,\n",
              " 'to\\nslaughter,\\nHis': 0.005813953488372093,\n",
              " 'transformed': 0.005813953488372093,\n",
              " 'until': 0.005813953488372093,\n",
              " 'unto': 0.011627906976744186,\n",
              " 'upon': 0.011627906976744186,\n",
              " 'we': 0.005813953488372093,\n",
              " 'were': 0.005813953488372093,\n",
              " 'with': 0.005813953488372093,\n",
              " 'withal.\\n\\nLADY': 0.005813953488372093,\n",
              " 'your': 0.005813953488372093}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUmn2v-K4w2l"
      },
      "source": [
        "Question 4:\r\n",
        "\r\n",
        "Write a function that takes the following three parameters: model, list of start words, number of sentences to generate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rrRjiXyuRiIM",
        "outputId": "cfb43a15-f8af-4419-cc6b-a6ed5c46eb1e"
      },
      "source": [
        "# Question 4\r\n",
        "def makeSentence(m,w,n):\r\n",
        "  sentence_finished = False\r\n",
        "  n = float(n)\r\n",
        "  sent = [0]*int(n)\r\n",
        "  tmp = 0.0\r\n",
        "  # Trigram\r\n",
        "  if m == 1:\r\n",
        "    text = w\r\n",
        "    while not sentence_finished: \r\n",
        "      r = 0.01 \r\n",
        "      for word in model_1[tuple(text[-2:])].keys():\r\n",
        "        accumulator = .0\r\n",
        "        accumulator += model_1[tuple(text[-2:])][word]\r\n",
        "        if accumulator >= r and tmp <= (n-1):\r\n",
        "          x = text + [word]\r\n",
        "          sent[int(tmp)] = x\r\n",
        "          tmp += 1.0\r\n",
        "        if tmp == (n):\r\n",
        "          sentence_finished = True\r\n",
        "          break\r\n",
        "  # Bigram\r\n",
        "  elif m == 2:\r\n",
        "      text = w\r\n",
        "      while not sentence_finished: \r\n",
        "        r = 0.001\r\n",
        "        for word in model_2[text[0]].keys():\r\n",
        "          accumulator = .0\r\n",
        "          accumulator += model_2[text[0]][word]\r\n",
        "          if accumulator >= r and tmp <= (n-1):\r\n",
        "            x = text + [word]\r\n",
        "            sent[int(tmp)] = x\r\n",
        "            tmp += 1.0      \r\n",
        "          if tmp == (n):\r\n",
        "            sentence_finished = True\r\n",
        "            break\r\n",
        "  return sent\r\n",
        "\r\n",
        "\r\n",
        "# Testing the function \r\n",
        "text_1 = [\"king\",\"of\"]\r\n",
        "text_2 = [\"that\"]\r\n",
        "\r\n",
        "tri = makeSentence(1,text_1,5)\r\n",
        "big = makeSentence(2,text_2,10)\r\n",
        "\r\n",
        "print('5 sentences with the Trigram model')\r\n",
        "print('-------------------------------------')\r\n",
        "print(tri)\r\n",
        "print()\r\n",
        "print()\r\n",
        "print('10 sentences with the Bigram model')\r\n",
        "print('-------------------------------------')\r\n",
        "print(big)\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 sentences with the Trigram model\n",
            "-------------------------------------\n",
            "[['king', 'of', 'pygmies,\\n'], ['king', 'of', 'smiles,'], ['king', 'of', 'courtesy,\\nand'], ['king', 'of', 'honor.\\nNo'], ['king', 'of', 'it?\\n\\nBASTARD,']]\n",
            "\n",
            "\n",
            "10 sentences with the Bigram model\n",
            "-------------------------------------\n",
            "[['that', 'good'], ['that', 'is'], ['that', 'we'], ['that', 'time'], ['that', 'with'], ['that', 'this'], ['that', 'will'], ['that', 'you'], ['that', 'your'], ['that', 'I']]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}