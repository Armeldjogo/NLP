{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_HW4.ipynb",
      "provenance": [],
      "mount_file_id": "1rgAxwDFzWhB22S4fqA65Xg8hg1OzNcOQ",
      "authorship_tag": "ABX9TyM5orVa6bQqvek0VJB9G+2x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Armeldjogo/NLP/blob/main/NLP_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLGBhRnGO-dG"
      },
      "source": [
        "Name: Armel Nsiangani\n",
        "\n",
        "Student ID#: 001-99-1988\n",
        "\n",
        "NLP - HW4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "6nE_dlWIOvdz",
        "outputId": "e27b969c-413b-44c3-acf0-33d2605b2a4b"
      },
      "source": [
        "# Downloading packages\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import classification_report\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import tensorflow_hub as hub\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set() \n",
        "from sklearn.feature_extraction.text import CountVectorizer # Bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF\n",
        "from sklearn.naive_bayes import MultinomialNB # Bayes\n",
        "from sklearn.ensemble import RandomForestClassifier # RF\n",
        "from sklearn.svm import SVC # SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn.metrics \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('movie_reviews')\n",
        "nltk.download('punkt')\n",
        "# Random seed\n",
        "from numpy.random import seed\n",
        "seed(2361)\n",
        "# For LSTM \n",
        "!pip install numpy==1.16.2\n",
        "# All the imports!\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "from sklearn.metrics import classification_report\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Collecting numpy==1.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/e7/6c780e612d245cca62bc3ba8e263038f7c144a96a54f877f3714a0e8427e/numpy-1.16.2-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 191kB/s \n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.2 has requirement numpy>=1.17, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.16.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ppzJQF5PpBY"
      },
      "source": [
        "# Preprocessing data\n",
        "# Unzip files\n",
        "import zipfile\n",
        "path_to_zip_file = \"/content/trainingandtestdata.zip\"\n",
        "directory_to_extract_to = \"/content/\"\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)\n",
        "\n",
        "# Renaming the file\n",
        "import os\n",
        "os.rename(r'/content/training.1600000.processed.noemoticon.csv',r'/content/training.csv')\n",
        "os.rename(r'/content/testdata.manual.2009.06.14.csv',r'/content/testing.csv')\n",
        "\n",
        "# Downloading data \n",
        "all_data_training = pd.read_csv(r\"/content/training.csv\", encoding = \"ISO-8859-1\")\n",
        "all_data_training.columns=['Polarity','ID','Date','Query','User Name','Tweet text']\n",
        "\n",
        "# Retrieve pos. & neg. tweets only\n",
        "pd.set_option('display.max_columns', None)\n",
        "data_N = all_data_training[all_data_training['Polarity'] == 0] # Negative tweets\n",
        "data_P = all_data_training[all_data_training['Polarity'] == 4] # Positive tweets\n",
        "neg_pos_data = all_data_training[(all_data_training['Polarity'] == 0) | (all_data_training['Polarity'] == 4)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHHdSVwcPCNx"
      },
      "source": [
        "Q1. Take the positive and the negative tweets only. Use Sklearn to split the dataset in 80% training, 20% testing splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLbx6uAwQAdR",
        "outputId": "e3fd5b74-9162-4150-8e61-99ae295a1dcd"
      },
      "source": [
        "# Question 1\n",
        "# Splitting data 80% - training & 20% - testing\n",
        "train, test = train_test_split(neg_pos_data, train_size= 0.8, test_size = 0.2)\n",
        "\n",
        "# Displaying the data\n",
        "print('Training set: ', )\n",
        "print('Size of set: ', train.shape)\n",
        "print(train.head())\n",
        "\n",
        "print()\n",
        "print('------------------------------------------------------------------------')\n",
        "print()\n",
        "\n",
        "print('Testing set: ', )\n",
        "print('Size of set: ', test.shape)\n",
        "print(test.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set: \n",
            "Size of set:  (1279999, 6)\n",
            "         Polarity          ID                          Date     Query  \\\n",
            "1327068         4  2015337727  Wed Jun 03 04:23:32 PDT 2009  NO_QUERY   \n",
            "867725          4  1677825654  Sat May 02 04:11:28 PDT 2009  NO_QUERY   \n",
            "191053          0  1969494674  Sat May 30 00:12:53 PDT 2009  NO_QUERY   \n",
            "266955          0  1989094615  Mon Jun 01 00:19:41 PDT 2009  NO_QUERY   \n",
            "1472944         4  2065462631  Sun Jun 07 08:38:46 PDT 2009  NO_QUERY   \n",
            "\n",
            "             User Name                                         Tweet text  \n",
            "1327068        DCBrent  @MarkDC Okay, no probs if you can't.  Just pla...  \n",
            "867725     PRMurphy147  @nobodysnews LOL, it was more like the sound o...  \n",
            "191053   rockerchick99  @gregstrong Emery is amazing! Sadly I have yet...  \n",
            "266955          Tripzy  @soBOMB my phone died on u  sorry lol and i ca...  \n",
            "1472944          kulit  loves that there's so much Federer love going ...  \n",
            "\n",
            "------------------------------------------------------------------------\n",
            "\n",
            "Testing set: \n",
            "Size of set:  (320000, 6)\n",
            "         Polarity          ID                          Date     Query  \\\n",
            "402563          0  2057966189  Sat Jun 06 14:00:20 PDT 2009  NO_QUERY   \n",
            "1558128         4  2185758509  Mon Jun 15 17:51:41 PDT 2009  NO_QUERY   \n",
            "1415200         4  2057173199  Sat Jun 06 12:30:33 PDT 2009  NO_QUERY   \n",
            "1112565         4  1972437668  Sat May 30 09:13:25 PDT 2009  NO_QUERY   \n",
            "706645          0  2256751496  Sat Jun 20 13:14:59 PDT 2009  NO_QUERY   \n",
            "\n",
            "           User Name                                         Tweet text  \n",
            "402563        kachen                Sorry for not saying goodbye  Kathy  \n",
            "1558128      vibanez  @lilxicanita aww mecheee you can be my friend....  \n",
            "1415200  ginotheoken  having my big brother open for me is a dream c...  \n",
            "1112565        WOnet  @TinkFan Can you tell @DancerDaniK that she is...  \n",
            "706645        adeeee  @thewitchbaby   Not really  I'm looking for an...  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbDg7XQdT14s"
      },
      "source": [
        " Q2. Use the code from the previous classes to build the following models (15 points):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvlnl6u2SmId",
        "outputId": "96eb90b2-7b84-44e4-ff8c-03fbf83a230e"
      },
      "source": [
        "# Question 2\n",
        "# Function to return models\n",
        "def createModels(classAlgName,vectorMethod,trainingSet):\n",
        "  # create model\n",
        "  model = make_pipeline(vectorMethod, classAlgName)\n",
        "  # fit model\n",
        "  model.fit(trainingSet['Tweet text'], trainingSet[['Polarity']].values)\n",
        "  return model\n",
        "\n",
        "# Model : SVM using TF-IDF, Naive Bayes using TF-IDF, Random Forest using TF-IDF\n",
        "model_1 = createModels(LinearSVC(),TfidfVectorizer(),train) # SVM using TF-IDF\n",
        "model_2 = createModels(MultinomialNB(),TfidfVectorizer(),train) # Naive Bayes using TF-IDF\n",
        "#model_3 = createModels(RandomForestClassifier(),TfidfVectorizer(),train) #Random Forest using TF-IDF"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJPXfCCKZLDU",
        "outputId": "d9f57d27-595f-4465-c0f7-d66334cd074b"
      },
      "source": [
        "# Tesing the models performance\n",
        "\n",
        "# SVM using TF-IDF\n",
        "test_vals = test[['Polarity']].values\n",
        "labels_1 = model_1.predict(test['Tweet text'])\n",
        "\n",
        "print('Results SVM using TF-IDF')\n",
        "print('-------------------------------')\n",
        "print('Precision:', sklearn.metrics.precision_score(test_vals,labels_1,average=\"binary\", pos_label= 4))\n",
        "print('Recall:', sklearn.metrics.recall_score(test_vals,labels_1,average=\"binary\", pos_label= 4))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels_1, test_vals, average='macro'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results SVM using TF-IDF\n",
            "-------------------------------\n",
            "Precision: 0.79442089124214\n",
            "Recall: 0.7998725023905802\n",
            "F1 Score: 0.7964350770685049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEY5vdcxZi3R",
        "outputId": "54a3185b-7988-46de-97fc-a457ee3c9912"
      },
      "source": [
        "# Naive Bayes using TF-IDF\n",
        "labels_2 = model_2.predict(test['Tweet text'])\n",
        "\n",
        "print('Results Naive Bayes using TF-IDF')\n",
        "print('---------------------------------')\n",
        "print('Precision:', sklearn.metrics.precision_score(test_vals,labels_2,average=\"binary\", pos_label= 4))\n",
        "print('Recall:', sklearn.metrics.recall_score(test_vals,labels_2,average=\"binary\", pos_label= 4))\n",
        "print('F1 Score:', sklearn.metrics.f1_score(labels_2, test_vals, average='macro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results Naive Bayes using TF-IDF\n",
            "---------------------------------\n",
            "Precision: 0.8012933649550493\n",
            "Recall: 0.7263988800209996\n",
            "F1 Score: 0.7726319283754856\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h17xX-yqUBBa"
      },
      "source": [
        "Q3. Use the code from the LSTM class to build a classifier for negative and positive\n",
        "sentiment tweets. Train the model with the training data split. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6pHT0LXUJFi",
        "outputId": "9fcfad86-cec4-487f-89ba-a27193fdba74"
      },
      "source": [
        "# Padding the DataFrames\n",
        "# The length of reviews\n",
        "tweet_length = 500\n",
        "# Padding the training data\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(train['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_train = tokenizer.texts_to_sequences(train['Tweet text'].values)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen= tweet_length)\n",
        "\n",
        "# Building the model\n",
        "vocab_size = len(word_index) + 1\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = vocab_size, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = tweet_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "print('LSTM class summary')\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM class summary\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           19045152  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 19,053,505\n",
            "Trainable params: 19,053,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-mtsEyZVBQl",
        "outputId": "bb60fbbd-c63f-4baa-f991-08c6d71d8ead"
      },
      "source": [
        "# Create the model\n",
        "y_train = np.array(train[['Polarity']].values)\n",
        "y_train[ y_train== 4] = 1\n",
        "\n",
        "model.fit(x_train,y_train,batch_size=1024,epochs=3, validation_split=0.2,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1000/1000 [==============================] - 382s 351ms/step - loss: 0.5136 - accuracy: 0.7425 - val_loss: 0.4101 - val_accuracy: 0.8129\n",
            "Epoch 2/3\n",
            "1000/1000 [==============================] - 348s 348ms/step - loss: 0.3687 - accuracy: 0.8363 - val_loss: 0.4128 - val_accuracy: 0.8125\n",
            "Epoch 3/3\n",
            "1000/1000 [==============================] - 350s 350ms/step - loss: 0.2971 - accuracy: 0.8739 - val_loss: 0.4382 - val_accuracy: 0.8046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb61a308390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW5gwg7BVVjJ",
        "outputId": "36cdefb9-fc3f-4e03-ffa2-3ecca39fbf6c"
      },
      "source": [
        "# Display performance\n",
        "# Padding the data\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(test['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_test = tokenizer.texts_to_sequences(test['Tweet text'].values)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen= tweet_length)\n",
        "y_test = np.array(test[['Polarity']].values)\n",
        "y_test[ y_test == 4] = 1\n",
        "\n",
        "# Labelling scores\n",
        "class_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Printing results\n",
        "predicted_classes = model.predict_classes(x_test)\n",
        "LSTM_report = classification_report(y_test, predicted_classes, target_names=class_names)\n",
        "print('Performance: LSTM')\n",
        "print(LSTM_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Performance: LSTM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.54      0.58      0.56    159997\n",
            "    Positive       0.55      0.51      0.53    160003\n",
            "\n",
            "    accuracy                           0.55    320000\n",
            "   macro avg       0.55      0.55      0.55    320000\n",
            "weighted avg       0.55      0.55      0.55    320000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WutlK8mAVbcK"
      },
      "source": [
        "Question: What can you say about the performance of this model?\n",
        "\n",
        "Surprisingly, the performance of the LSTM appears to be lower than the other models. Additionally, the scores for precision, recall, and f1 appear to be very similar. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2jYLEouVif9"
      },
      "source": [
        "Q4. Compare all models together in terms of Precision, Recall and F1 score. Put all of these numbers in a nicely formatted dataframe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgXt_lCQVqHO",
        "outputId": "974b1b64-ffe5-4209-f699-1a43542dab7b"
      },
      "source": [
        "# Question 4\n",
        "# Precision \n",
        "P_1 = sklearn.metrics.precision_score(test_vals,labels_1,average=\"binary\", pos_label= 4) # SVM\n",
        "P_2 = sklearn.metrics.precision_score(test_vals,labels_2,average=\"binary\", pos_label= 4) # NB\n",
        "P_3 = LSTM_report[0:][291:296]\n",
        "\n",
        "prec = [P_1, P_2, P_3]\n",
        "\n",
        "# Recall\n",
        "R_1 = sklearn.metrics.recall_score(test_vals,labels_1,average=\"binary\", pos_label= 4)\n",
        "R_2 = sklearn.metrics.recall_score(test_vals,labels_2,average=\"binary\", pos_label= 4)\n",
        "R_3 = LSTM_report[0:][301:305]\n",
        "\n",
        "rec = [R_1, R_2, R_3]\n",
        "\n",
        "# F-1 score \n",
        "F_1 = sklearn.metrics.f1_score(labels_1, test_vals, average='macro')\n",
        "F_2 = sklearn.metrics.f1_score(labels_2, test_vals, average='macro')\n",
        "F_3 = LSTM_report[0:][311:315]\n",
        "\n",
        "f1_score = [F_1, F_2, F_3]\n",
        "\n",
        "model_name = ['SVM', 'Naive Bayes', 'LSTM']\n",
        "\n",
        "# Create a DataFrame \n",
        "print('Review of Models')\n",
        "dataFrame_with_scores = pd.DataFrame({\"model name\": model_name, \"precision\": prec, \"recall\":rec, \"f1_score\":f1_score})\n",
        "\n",
        "print(dataFrame_with_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review of Models\n",
            "    model name precision    recall  f1_score\n",
            "0          SVM  0.794421  0.799873  0.796435\n",
            "1  Naive Bayes  0.801293  0.726399  0.772632\n",
            "2         LSTM     0.55       0.55      0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRtoU0pxVuNO"
      },
      "source": [
        "Which model performs the best? \n",
        "\n",
        "According to the results above, SVM using TF-IDF\n",
        "\n",
        "Why do you think this is? \n",
        "\n",
        "The reason why I am choosing SVM is because it's overall score for precision, recall, and f1 is about 0.8, which is higher than any other models.\n",
        "\n",
        "What do you think you can do to improve performance?\n",
        "\n",
        "Here, the analysis was done without adequate pre-processing steps. I believe the performance can be improved by processing the data (e.g. removing stopwords) before creating the models, and prediting the model results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMvR6Ae1V7Ji"
      },
      "source": [
        "Q5. Add to the comparison of #4 a the manually calculated precision, recall and F1 score using VADER and their suggested defaults to categorize the test split tweets in positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf1hyjx2WEJY"
      },
      "source": [
        "# Question 5\n",
        "# Get sentiment score - Using VADER\n",
        "sentiment_score = []\n",
        "tweets = neg_pos_data['Tweet text'].values\n",
        "\n",
        "for word in tweets:\n",
        "  sia = SIA()\n",
        "  scores = sia.polarity_scores(word)\n",
        "  sentiment_score.append(scores)\n",
        "\n",
        "x = sentiment_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5ESYD-QCIUo"
      },
      "source": [
        "# Labeled Positive vs Negative\n",
        "match_neg = 0\n",
        "mismatch_neg = 0\n",
        "match_pos = 0\n",
        "mismatch_pos = 0\n",
        "comp_score_pos = []\n",
        "comp_score_neg = []\n",
        "# Negative section\n",
        "for i in range(0,len(data_N)):\n",
        "  comp_score_neg.append(x[i]['compound'])\n",
        "  if comp_score_neg[i] <= -0.05:\n",
        "    match_neg += 1\n",
        "  else:\n",
        "    mismatch_neg += 1\n",
        "# Positive section\n",
        "k = 0\n",
        "for i in range(len(data_N),len(neg_pos_data)):\n",
        "  comp_score_pos.append(x[i]['compound'])\n",
        "  if comp_score_pos[k] >= 0.05:\n",
        "    match_pos += 1\n",
        "  else:\n",
        "    mismatch_pos += 1\n",
        "  k += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "1ISCY7mxOU-3",
        "outputId": "96df5f6c-07eb-4f92-ebc1-4e22b006f791"
      },
      "source": [
        "# Printing results\n",
        "# Negative results\n",
        "y = comp_score_neg\n",
        "x = range(0,len(comp_score_neg))\n",
        "plt.hist(y) \n",
        "plt.title('Compound score distribution for negative tweets')\n",
        "plt.xlabel('Compound score')\n",
        "plt.ylabel('# of reviews')\n",
        "plt.show()\n",
        "print('Figure 1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Figure 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "oNi9CH7kP-ph",
        "outputId": "8a0a2e20-4ad5-4cae-ae5f-22973f7524dd"
      },
      "source": [
        "# Positive results\n",
        "y = comp_score_pos\n",
        "x = range(0,len(comp_score_pos))\n",
        "plt.hist(y) \n",
        "plt.title('Compound score distribution for positive tweets')\n",
        "plt.xlabel('Compound score')\n",
        "plt.ylabel('# of reviews')\n",
        "plt.show()\n",
        "print('Figure 2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Figure 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIVLypixR6oi"
      },
      "source": [
        "# Computing Precision, Recall and F1 score\n",
        "# Precision TP/(TP + FP):\n",
        "prec_VADER = match_pos/ (match_pos + mismatch_neg)\n",
        "\n",
        "# recall TP/(TP + FN)\n",
        "rec_VADER = match_pos/ (match_pos + mismatch_pos)\n",
        "\n",
        "# F1 score 2*Prec*Recall/(Prec + Recall)\n",
        "f1_VADER = 2*prec_VADER*rec_VADER/(prec_VADER + rec_VADER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRIaZioUV6I",
        "outputId": "559df4c8-ccd2-43b3-cc71-2d03088c31e5"
      },
      "source": [
        "# Updated Q4 Table \n",
        "prec.append(prec_VADER)\n",
        "rec.append(rec_VADER)\n",
        "f1_score.append(f1_VADER)\n",
        "model_name.append('VADER')\n",
        "\n",
        "# Create a DataFrame \n",
        "print('Review of Models')\n",
        "dataFrame_with_scores = pd.DataFrame({\"model name\": model_name, \"precision\": prec, \"recall\":rec, \"f1_score\":f1_score})\n",
        "\n",
        "print(dataFrame_with_scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review of Models\n",
            "    model name precision    recall  f1_score\n",
            "0          SVM  0.794421  0.799873  0.796435\n",
            "1  Naive Bayes  0.801293  0.726399  0.772632\n",
            "2         LSTM     0.55       0.55      0.55\n",
            "3        VADER  0.514112  0.615003   0.56005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju-2bdhJWGdb"
      },
      "source": [
        "Question:\n",
        "Is this approach as good as the previous\n",
        "ones? Why do you think this is?\n",
        "\n",
        "Looking at the performance results, i do not think that VADER is as good as the other methods. In fact, its scores are one of the lowest on the performance table. This is probably due to its intrinsic methodological steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS5eV7bYWMj6"
      },
      "source": [
        "Bonus: \n",
        "\n",
        "Try the following things to improve the LSTM model:\n",
        "\n",
        "\n",
        "1) Use 90% training data, 10% testing\n",
        "\n",
        "\n",
        "2) Remove stopwords from the tweets.\n",
        "\n",
        "\n",
        "3) Remove all user mentions for the tweets (@something)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQQZxy2xWZqH",
        "outputId": "642dcff3-9985-44e4-c773-3f8579366ce8"
      },
      "source": [
        "# Bonus\n",
        "# 1 - 90% training | 10% testing\n",
        "\n",
        "train_1, test_1 = train_test_split(neg_pos_data, train_size= 0.9, test_size = 0.1)\n",
        "tweet_length = 500\n",
        "\n",
        "\n",
        "# Padding the training data\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(train_1['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_train_1 = tokenizer.texts_to_sequences(train_1['Tweet text'].values)\n",
        "x_train_1 = sequence.pad_sequences(x_train_1, maxlen= tweet_length) \n",
        "\n",
        "\n",
        "y_train_1 = np.array(train_1[['Polarity']].values)\n",
        "y_train_1[ y_train_1== 4] = 1\n",
        "\n",
        "model.fit(x_train_1,y_train_1,batch_size=256,epochs=3, validation_split=0.2,verbose=1) # batch size original = 256\n",
        "\n",
        "# Display performance\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(test_1['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_test_1 = tokenizer.texts_to_sequences(test_1['Tweet text'].values)\n",
        "x_test_1 = sequence.pad_sequences(x_test_1, maxlen= tweet_length)\n",
        "\n",
        "y_test_1 = np.array(test_1[['Polarity']].values)\n",
        "y_test_1[ y_test_1 == 4] = 1\n",
        "\n",
        "# Labelling scores\n",
        "class_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Printing results\n",
        "predicted_classes_1 = model.predict_classes(x_test_1)\n",
        "LSTM_report = classification_report(y_test_1, predicted_classes_1, target_names=class_names)\n",
        "print('Performance: LSTM - 90/10 splitting data')\n",
        "print(LSTM_report)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4500/4500 [==============================] - 1008s 217ms/step - loss: 0.4686 - accuracy: 0.7746 - val_loss: 0.3955 - val_accuracy: 0.8205\n",
            "Epoch 2/3\n",
            "4500/4500 [==============================] - 983s 218ms/step - loss: 0.3456 - accuracy: 0.8489 - val_loss: 0.4092 - val_accuracy: 0.8150\n",
            "Epoch 3/3\n",
            "4500/4500 [==============================] - 978s 217ms/step - loss: 0.2745 - accuracy: 0.8860 - val_loss: 0.4312 - val_accuracy: 0.8096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Performance: LSTM - 90/10 splitting data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.56      0.56      0.56     80156\n",
            "    Positive       0.56      0.56      0.56     79844\n",
            "\n",
            "    accuracy                           0.56    160000\n",
            "   macro avg       0.56      0.56      0.56    160000\n",
            "weighted avg       0.56      0.56      0.56    160000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI9MANgHyUww",
        "outputId": "94a5352e-03a4-4b1c-9d97-38071f104829"
      },
      "source": [
        "# 2 - Remove stopwords from the tweets\n",
        "\n",
        "def returnFilteredToken(reviews):\n",
        "  stop_words = set(stopwords.words('english')) \n",
        "  filter_rev = []\n",
        "  for word in reviews:\n",
        "    word_t = word_tokenize(word)\n",
        "    filtered_word = [w for w in word_t if not w in stop_words]\n",
        "    filter_rev.append(filtered_word)  \n",
        "  return filter_rev\n",
        "\n",
        "data_filtered = returnFilteredToken(neg_pos_data['Tweet text'])\n",
        "\n",
        "# Data Frame after removing stopwords\n",
        "def returnListOfString(s):\n",
        "  s_new = []\n",
        "  for i in s:\n",
        "    l_2_str = ' '.join([str(elem) for elem in i]) \n",
        "    s_new.append(l_2_str)\n",
        "  return s_new\n",
        "\n",
        "# Array for polarity\n",
        "pol = np.array(neg_pos_data[['Polarity']].values)\n",
        "array_pol = []\n",
        "for i in range(0,len(pol)):\n",
        "  array_pol.append(pol[i][0])\n",
        "\n",
        "data_filtered_n = returnListOfString(data_filtered)\n",
        "all_data_filt = pd.DataFrame({\"Polarity\": array_pol,\"Tweet text\": data_filtered_n}) \n",
        "\n",
        "# Model & Performance\n",
        "\n",
        "train_2, test_2 = train_test_split(all_data_filt, train_size= 0.9, test_size = 0.1)\n",
        "tweet_length = 500\n",
        "\n",
        "\n",
        "# Padding the training data\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(train_2['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_train_2 = tokenizer.texts_to_sequences(train_2['Tweet text'].values)\n",
        "x_train_2 = sequence.pad_sequences(x_train_2, maxlen= tweet_length) \n",
        "\n",
        "\n",
        "y_train_2 = np.array(train_2[['Polarity']].values)\n",
        "y_train_2[ y_train_2== 4] = 1\n",
        "\n",
        "model.fit(x_train_2,y_train_2,batch_size=256,epochs=3, validation_split=0.2,verbose=1) \n",
        "\n",
        "# Display performance\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(test_2['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_test_2 = tokenizer.texts_to_sequences(test_2['Tweet text'].values)\n",
        "x_test_2 = sequence.pad_sequences(x_test_2, maxlen= tweet_length)\n",
        "\n",
        "y_test_2 = np.array(test_2[['Polarity']].values)\n",
        "y_test_2[ y_test_2 == 4] = 1\n",
        "\n",
        "# Labelling scores\n",
        "class_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Printing results\n",
        "predicted_classes_2 = model.predict_classes(x_test_2)\n",
        "LSTM_report = classification_report(y_test_2, predicted_classes_2, target_names=class_names)\n",
        "print('Performance: LSTM - Stopword removed')\n",
        "print(LSTM_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Performance: LSTM - Stopword removed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.54      0.56      0.55     80143\n",
            "    Positive       0.54      0.52      0.53     79857\n",
            "\n",
            "    accuracy                           0.54    160000\n",
            "   macro avg       0.54      0.54      0.54    160000\n",
            "weighted avg       0.54      0.54      0.54    160000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxJqD11t0WY2",
        "outputId": "1185abf2-3bf3-422d-b3db-071d1f1cbf7a"
      },
      "source": [
        "# 3 - Remove user mention\n",
        "def returnFilteredToken(reviews):\n",
        "  stop_words = set(stopwords.words('english')) \n",
        "  filter_rev = []\n",
        "  for word in reviews:\n",
        "    word_t = word_tokenize(word)\n",
        "    filtered_word = [w for w in word_t if not w in stop_words]\n",
        "    filter_rev.append(filtered_word)  \n",
        "  return filter_rev\n",
        "\n",
        "data_filtered = returnFilteredToken(neg_pos_data['Tweet text']) \n",
        "\n",
        "number_of_empty = 0\n",
        "# Removing all user metion (@ something)\n",
        "for i in range(0,len(data_filtered)):\n",
        "  if not data_filtered[i]:\n",
        "    number_of_empty += 1\n",
        "  else:\n",
        "    if data_filtered[i][0] == '@':\n",
        "      del data_filtered[i][0]\n",
        "      del data_filtered[i][0]\n",
        "\n",
        "# Data Frame after removing stopwords\n",
        "def returnListOfString(s):\n",
        "  s_new = []\n",
        "  for i in s:\n",
        "    l_2_str = ' '.join([str(elem) for elem in i]) \n",
        "    s_new.append(l_2_str)\n",
        "  return s_new\n",
        "\n",
        "# Array for polarity\n",
        "pol = np.array(neg_pos_data[['Polarity']].values)\n",
        "array_pol = []\n",
        "for i in range(0,len(pol)):\n",
        "  array_pol.append(pol[i][0])\n",
        "\n",
        "data_filtered_n = returnListOfString(data_filtered)\n",
        "all_data_filt = pd.DataFrame({\"Polarity\": array_pol,\"Tweet text\": data_filtered_n}) \n",
        "\n",
        "# Model & Performance\n",
        "\n",
        "train_2, test_2 = train_test_split(all_data_filt, train_size= 0.9, test_size = 0.1)\n",
        "tweet_length = 500\n",
        "\n",
        "\n",
        "# Padding the training data\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(train_2['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_train_2 = tokenizer.texts_to_sequences(train_2['Tweet text'].values)\n",
        "x_train_2 = sequence.pad_sequences(x_train_2, maxlen= tweet_length)\n",
        "\n",
        "\n",
        "y_train_2 = np.array(train_2[['Polarity']].values)\n",
        "y_train_2[ y_train_2== 4] = 1 \n",
        "\n",
        "model.fit(x_train_2,y_train_2,batch_size=256,epochs=3, validation_split=0.2,verbose=1)\n",
        "\n",
        "# Display performance\n",
        "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(test_2['Tweet text'].values)\n",
        "word_index = tokenizer.word_index\n",
        "x_test_2 = tokenizer.texts_to_sequences(test_2['Tweet text'].values)\n",
        "x_test_2 = sequence.pad_sequences(x_test_2, maxlen= tweet_length)\n",
        "\n",
        "y_test_2 = np.array(test_2[['Polarity']].values)\n",
        "y_test_2[ y_test_2 == 4] = 1\n",
        "\n",
        "# Labelling scores\n",
        "class_names = [\"Negative\", \"Positive\"]\n",
        "\n",
        "# Printing results\n",
        "predicted_classes_2 = model.predict_classes(x_test_2)\n",
        "LSTM_report = classification_report(y_test_2, predicted_classes_2, target_names=class_names)\n",
        "print('Performance: LSTM - User mentioned removed')\n",
        "print(LSTM_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "4500/4500 [==============================] - 710s 151ms/step - loss: 0.4910 - accuracy: 0.7604 - val_loss: 0.4334 - val_accuracy: 0.7975\n",
            "Epoch 2/3\n",
            "4500/4500 [==============================] - 673s 149ms/step - loss: 0.4040 - accuracy: 0.8148 - val_loss: 0.4325 - val_accuracy: 0.7997\n",
            "Epoch 3/3\n",
            "4500/4500 [==============================] - 673s 150ms/step - loss: 0.3675 - accuracy: 0.8349 - val_loss: 0.4421 - val_accuracy: 0.7970\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Performance: LSTM - User mentioned removed\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.54      0.55      0.55     80143\n",
            "    Positive       0.54      0.54      0.54     79857\n",
            "\n",
            "    accuracy                           0.54    160000\n",
            "   macro avg       0.54      0.54      0.54    160000\n",
            "weighted avg       0.54      0.54      0.54    160000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWmB-bSUvavz"
      },
      "source": [
        " Did this change the results in any way? \n",
        " No, the LSTM performance did not significantly improved for 90-10 dataset, without stopwords, or after removing the tweets mention.\n",
        "\n",
        "\n",
        " Why do you think so?\n",
        " Becuase LSTM uses a recurrent neural method, that repeatedly process the data. So, the results is the most accurate results, regardless of additional pre-processing steps."
      ]
    }
  ]
}